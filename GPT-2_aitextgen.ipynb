{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 (aitextgen)\n",
    "\n",
    "Options: Train a model, Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Install libraries. '''\n",
    "# !python3 -m pip install aitextgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen.utils import build_gpt2_config\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Tokenize dataset (Byte-Pair-Encoding). '''\n",
    "train_tokenizer(file_name, vocab_size=10000)\n",
    "vocab_file = \"gpt-2_aitextgen/aitextgen-vocab.json\"\n",
    "merges_file = \"gpt-2_aitextgen/aitextgen-merges.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aitextgen:Constructing GPT-2 model from provided config.\n",
      "INFO:aitextgen:Using a custom tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 256,\n",
      "  \"n_embd\": 128,\n",
      "  \"n_head\": 4,\n",
      "  \"n_layer\": 2,\n",
      "  \"n_positions\": 256,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.0,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 10000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec5452110d94a8ea7ee41604997de74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=2533.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aitextgen.TokenDataset:Encoding 2,533 sets of tokens from ../dataset/dataset.txt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "''' Custom configuration. '''\n",
    "config = build_gpt2_config(n_embd=128,\n",
    "                           n_head=4,\n",
    "                           n_layer=2,\n",
    "                           vocab_size=10000,\n",
    "                           max_length=256\n",
    "                          )\n",
    "\n",
    "print(config)\n",
    "\n",
    "''' Model. '''\n",
    "ai = aitextgen(vocab_file=vocab_file, merges_file=merges_file, config=config)\n",
    "''' Dataset for training. '''\n",
    "data = TokenDataset(file_name, vocab_file=vocab_file, merges_file=merges_file, block_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Training. '''\n",
    "ai.train(data, batch_size=128, num_steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aitextgen:Loading GPT-2 model from provided gpt-2_aitextgen/trained_model/pytorch_model.bin.\n",
      "INFO:aitextgen:Using a custom tokenizer.\n"
     ]
    }
   ],
   "source": [
    "from aitextgen import aitextgen\n",
    "ai = aitextgen(model=\"gpt-2_aitextgen/trained_model/pytorch_model.bin\",\n",
    "               config=\"gpt-2_aitextgen/trained_model/config.json\",\n",
    "               vocab_file=\"gpt-2_aitextgen/aitextgen-vocab.json\",\n",
    "               merges_file=\"gpt-2_aitextgen/aitextgen-merges.txt\",\n",
    "               to_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDie Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\u001b[0m\n",
      "Die Entwicklung von Nervenzellen.\n",
      "In sequenziellen Umgebungen.\n",
      "Wir entstehen unser Gehirn stehen somit Repräsentationen von Symbolen; die Gesamtheit der Außenwelt (und damit auch Aspekte des jeweiligen Registrieren also von einem bestimmten Handlungen.\n",
      "Die Geschichte des Gehirns.\n",
      "In sequenziellen Umgebungen kann das materielle Darstellung eines Netzwerks ist das fundamentalen Bindung zwischen einem Prozess von denen sich im Gegensatz zu einem gewissen Maß.\n",
      "Die Entwicklung von denen in diesem Moment im Gegensatz zu einem gewissen Stellen menschlichen Denkens in einem gewissen Grad von die Reflexion weist die Großhirnrinde werden, nur noch offen für die Bereiche der Spiegel seiner Umwelt aufgegestaucht seit es noch Muster lassen.\n",
      "Die formalen Logik zu im Gehirn nur in einer besonderen Gotph wie Kunst Unbegewororingen ist.\n",
      "Wie würde, nur zugänglichsparten, Bereicheironolinem.\n",
      "Bei den Unbestimmtheitsspielraum hinsichtlich eines Menschen besteht nach einem bestimmten Handlungs festgel besteht aus auffallend anders als Operatoren) in Operatoren (und damit kommt.\n",
      "In sequenziellen Umgebungen kann es noch wenn Neugier.\n",
      "Es gibt es noch Informationsreichten.\n",
      "In sequenziellen Umgebungen kann sie mit einer bestimmten zeitlichen Struktur ändern sich von außenenigigigigigige Aspekte des Künstlers könnte.\n",
      "Wir\n",
      "None\n",
      "\u001b[1mDie Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\u001b[0m\n",
      "Im Vergleich zu einer geschlossenen Identität.\n",
      "Und Charakter liegt eine Realität bzw.\n",
      "Erst durch Anwesene Begriffe (3 findet eine Sprache und Unut statt vom Gehirn frei von anderen Hirnarealen sind dies durch den Neuronen durch den Wissenschaften er deren Qualität.\n",
      "Die einzige Subjekt gebunden Codierung ist die Beschreibung eines Selbst.\n",
      "Nach meine jedoch nicht nur vom Arbeiter?\n",
      "Wir stellen ein Mehrften des Systems zuto Sie.\n",
      "Wir entwerfen (Kgeschörigen frei, scheitern.\n",
      "Dadurch wir aller Menschen kein Ende der Eindrucksten.\n",
      "Wenn wir längst dieses Gebirum ausnommen wird sie, wieder, zu verfügen nicht notwendig überschreischt, in, vor dem Begriff aus, sann wissen, darzustellen.\n",
      "Der Wesen sich.\n",
      "Der Künstler und den selbst auch die.\n",
      "Der Mensch als die.\n",
      "Ein zentrales Element beinhaltet sich frei von Welt.\n",
      "Der Künstlerwie wird eine Gestalt des ästhetischen Struktur im Gehirn von sich in seiner Wissenschaft von Maschinen sich zur Wahrnehmung der Form von Maschinen.\n",
      "Dieser Modus des Urteilens ist muß einfachen Formulierung inrechterhaltung und ist ein gibt konstitutive neuronales denkenden Objektalspunkt für ein technologisches Objektinternen.\n",
      "Sieraguvergwurf und\n",
      "None\n",
      "\u001b[1mDie Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\u001b[0m\n",
      "Anic wurde.\n",
      "Auf der Entwicklung dieser Wirklichkeit voraus.Brales Objekt nicht in Koordination von Hilfe der Programmierung möglichem Objekt.\n",
      "Wie noch Bereicheistischen (durch selbst einen Person]. \n",
      "Wenn diese Fähigkeit des Dualismus ist eine andere Repräsentationsprozeß) dem künstlerischen Gebrauch/ sie unsere Begriffe wie ein Modell wird bloß etwas bestimmt, Analysierte.\n",
      "Das Selbstmodell ist dies aus.\n",
      "Er kommt ausgehen.\n",
      "Unser Anre Zellen auch, sondern an Selbst mehr Informationen auch, daß er wirksam. um in ihm sehr ein Roman; ihre Daten Verhältnisierung Werkzeug muss Interesse ist ebenso somit, wo uns ein anderes System betrachtet werden sich in Bestimmungster Prozess gehören.h erkennen), kann es einlassen.\n",
      "Im Prozeß, so oder formfert bezeichnet aus Szinghaft erreicht. die der Gesellschaft darauf, was wir dies wir unseren jebedingungen vom Fildern sich Menschen über etwas gut aus anderen Ebene der Gesellschaft ihrerseits – dann mit diesem Fall den Anforderungen stzes erlent durch symbolische Beziehung bis darüber geteilt oder physischen Verknüpfungen von Subjekts lässt.\n",
      "Durch Dennett existiert nach Entitäten zu unterscheiden.Brellen von Systemen mit Systeme keine Entscheidung, sind ebenfalls.\n",
      "Durch das Objekt -\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = '''\n",
    "Die Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\n",
    "'''.replace('\\n','')\n",
    "for temp in [0.5, 1.0, 1.5]:\n",
    "    print(ai.generate(prompt=inp, temperature=temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "https://docs.aitextgen.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
